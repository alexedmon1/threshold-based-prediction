{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FreeSurfer Example - Python API Usage\n",
    "\n",
    "This notebook demonstrates how to use the threshold-based prediction package programmatically with FreeSurfer neuroimaging data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example shows:\n",
    "1. Data preparation from FreeSurfer outputs\n",
    "2. Threshold-based SVM analysis\n",
    "3. Results evaluation and visualization\n",
    "4. HTML report generation\n",
    "\n",
    "**Dataset**: 20 synthetic human subjects with FreeSurfer-processed brain MRI data and varying exposure levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required packages and set up paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Import threshold prediction modules\n",
    "from threshold_prediction.data.pipeline_factory import DataPipelineFactory\n",
    "from threshold_prediction.models.threshold_analyzer import ThresholdAnalyzer\n",
    "from threshold_prediction.evaluation import (\n",
    "    ResultsEvaluator, \n",
    "    ResultsVisualizer, \n",
    "    HTMLReportGenerator\n",
    ")\n",
    "\n",
    "# Set paths\n",
    "example_dir = Path(\"../sample_data/freesurfer_example\")\n",
    "config_file = example_dir / \"freesurfer_example_config.yaml\"\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"✓ Example directory: {example_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation\n",
    "\n",
    "Load FreeSurfer data and merge with exposure metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline from configuration file\n",
    "print(\"Loading configuration...\")\n",
    "pipeline = DataPipelineFactory.from_config_file(config_file)\n",
    "\n",
    "print(f\"Pipeline type: {pipeline.config.pipeline.type}\")\n",
    "print(f\"Subjects directory: {pipeline.config.human.subjects_dir}\")\n",
    "print(f\"Number of subjects: {len(pipeline.config.human.subjects_list)}\")\n",
    "print(f\"Metadata file: {pipeline.config.standardization.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data preparation pipeline\n",
    "print(\"Running data preparation pipeline...\")\n",
    "data = pipeline.run(output_path=example_dir / \"api_prepared_data.csv\")\n",
    "\n",
    "print(f\"\\n✓ Data prepared: {data.shape[0]} subjects, {data.shape[1]} features\")\n",
    "print(f\"\\nColumns: {list(data.columns[:10])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the prepared data\n",
    "print(\"First few rows of prepared data:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check exposure variable distribution\n",
    "print(\"Exposure variable statistics:\")\n",
    "print(data[['exposure_group', 'exposure_dose', 'years_exposure']].describe())\n",
    "\n",
    "print(\"\\nExposure groups:\")\n",
    "print(data['exposure_group'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Threshold Analysis\n",
    "\n",
    "Scan different threshold values to find optimal classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = ThresholdAnalyzer()\n",
    "\n",
    "# Load prepared data\n",
    "analyzer.load_data(example_dir / \"api_prepared_data.csv\")\n",
    "\n",
    "print(f\"✓ Data loaded: {analyzer.data.shape[0]} subjects\")\n",
    "print(f\"✓ Features: {analyzer.data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run threshold scan\n",
    "print(\"Scanning thresholds from 0.0 to 2.0 (step 0.2)...\\n\")\n",
    "\n",
    "results_df = analyzer.scan_thresholds(\n",
    "    target_variable=\"exposure_dose\",\n",
    "    threshold_range=(0.0, 2.0),\n",
    "    threshold_step=0.2\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Threshold scan complete\")\n",
    "print(f\"✓ Tested {len(results_df)} thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "print(\"Threshold scan results:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold\n",
    "best_idx = results_df['accuracy'].idxmax()\n",
    "best_threshold = results_df.loc[best_idx, 'threshold']\n",
    "best_accuracy = results_df.loc[best_idx, 'accuracy']\n",
    "\n",
    "print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.1%}\")\n",
    "print(f\"Group sizes: {int(results_df.loc[best_idx, 'n_low'])} low / {int(results_df.loc[best_idx, 'n_high'])} high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Results Evaluation\n",
    "\n",
    "Analyze results and identify key thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluator\n",
    "evaluator = ResultsEvaluator(analyzer.results)\n",
    "\n",
    "# Get summary statistics\n",
    "summary = evaluator.get_summary()\n",
    "\n",
    "print(\"Analysis Summary:\")\n",
    "print(f\"  Total thresholds tested: {summary['n_thresholds']}\")\n",
    "print(f\"  Best threshold: {summary['best_threshold']:.4f}\")\n",
    "print(f\"  Best accuracy: {summary['best_accuracy']:.1%}\")\n",
    "print(f\"  Mean accuracy: {summary['mean_accuracy']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect key thresholds (inflection points)\n",
    "key_thresholds = evaluator.find_key_thresholds(target_variable=\"exposure_dose\")\n",
    "\n",
    "print(\"Key Thresholds (Inflection Points):\")\n",
    "for i, kt in enumerate(key_thresholds, 1):\n",
    "    print(f\"\\n{i}. Threshold: {kt['threshold']:.4f}\")\n",
    "    print(f\"   Accuracy: {kt['accuracy']:.1%}\")\n",
    "    print(f\"   Reason: {kt['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualization\n",
    "\n",
    "Create plots to visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizer\n",
    "visualizer = ResultsVisualizer(analyzer.results)\n",
    "\n",
    "# Plot accuracy vs threshold\n",
    "fig = visualizer.plot_accuracy_vs_threshold(target_variable=\"exposure_dose\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Accuracy plot generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for best threshold\n",
    "fig = visualizer.plot_confusion_matrix(\n",
    "    threshold=best_threshold,\n",
    "    target_variable=\"exposure_dose\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics comparison\n",
    "fig = visualizer.plot_metrics_comparison(target_variable=\"exposure_dose\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Metrics comparison generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate HTML Report\n",
    "\n",
    "Create a comprehensive HTML report with all results and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTML report\n",
    "report_gen = HTMLReportGenerator(evaluator, visualizer)\n",
    "\n",
    "report_path = example_dir / \"api_report.html\"\n",
    "report_gen.generate_html_report(\n",
    "    output_path=report_path,\n",
    "    target_variable=\"exposure_dose\"\n",
    ")\n",
    "\n",
    "print(f\"✓ HTML report generated: {report_path}\")\n",
    "print(f\"\\nOpen the report in your browser to view:\")\n",
    "print(f\"  file://{report_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete Python API workflow:\n",
    "\n",
    "1. ✓ **Data Preparation**: Loaded FreeSurfer data and merged with exposure metadata\n",
    "2. ✓ **Threshold Analysis**: Scanned thresholds to find optimal classification\n",
    "3. ✓ **Results Evaluation**: Analyzed performance metrics and identified key thresholds\n",
    "4. ✓ **Visualization**: Created plots for accuracy, confusion matrix, and metrics\n",
    "5. ✓ **Report Generation**: Produced comprehensive HTML report\n",
    "\n",
    "### Key Results\n",
    "\n",
    "- **Optimal Threshold**: 0.6\n",
    "- **Classification Accuracy**: 95%\n",
    "- **Interpretation**: Brain imaging patterns successfully distinguish between subjects with exposure below vs above 0.6\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Modify threshold range and step size for different resolutions\n",
    "- Try different cross-validation methods (k-fold vs leave-one-out)\n",
    "- Select specific brain regions for analysis\n",
    "- Apply to your own FreeSurfer data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
